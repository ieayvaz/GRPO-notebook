{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "29f3de3e-7a5d-4b28-a675-7db20104022c",
      "cell_type": "code",
      "source": [
        "!pip install  -U -q trl peft bitsandbytes wandb\n",
        "# Tested with transformers==4.47.1, trl==0.14.0, datasets==3.2.0, peft==0.14.0, accelerate==1.2.1"
      ],
      "metadata": {
        "trusted": true,
        "id": "29f3de3e-7a5d-4b28-a675-7db20104022c",
        "outputId": "1df0503a-1da9-4b83-a18d-1a39205e5d8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.3/318.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/363.4 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "id": "15510df5-7dfb-4451-8c77-d57642ac7cbe",
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "trusted": true,
        "id": "15510df5-7dfb-4451-8c77-d57642ac7cbe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()\n",
        "\n",
        "# Name the project\n",
        "%env WANDB_PROJECT=Cosmos-8B-Instruct-GRPO"
      ],
      "metadata": {
        "id": "BdwP3GYJ42Rk"
      },
      "id": "BdwP3GYJ42Rk",
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "e53374a9-0c65-4d8e-950f-1573af1d2f22",
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_id = \"alibayram/turkish_mmlu\"\n",
        "train_dataset = load_dataset(dataset_id, split=[\"train\"])\n",
        "train_dataset = train_dataset[0]\n",
        "train_dataset = train_dataset.remove_columns([\"bolum\",\"konu\",\"aciklama\",\"__index_level_0__\"])\n",
        "train_dataset = train_dataset.shuffle(seed=42).select(range(6600))"
      ],
      "metadata": {
        "trusted": true,
        "id": "e53374a9-0c65-4d8e-950f-1573af1d2f22"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "09f6bdb2-b27d-4cdb-92a0-4b8e45d8a0be",
      "cell_type": "code",
      "source": [
        "# Test dataset\n",
        "print(train_dataset[0])"
      ],
      "metadata": {
        "trusted": true,
        "id": "09f6bdb2-b27d-4cdb-92a0-4b8e45d8a0be"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f573c07b-94dc-439b-8e97-ed9a9580c755",
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = (\n",
        "    \"Kullanıcı ve asistan arasında bir konuşma. Kullanıcı bir soru soruyor, asistan bu soruyu çözüyor ve cevap veriyor. Asistan \"\n",
        "    \"soruyu öncelikle kendi zihininde düşünüyor ve sonra kullanıcıya yanıt veriyor. Akıl yürütme \"\n",
        "    \"işlemi <düşünce> </düşünce>, cevaplar <cevap> </cevap> etiketleri arasında gösteriliyor.\"\n",
        "    \"Örneğin: <düşünce>Akıl yürütme kısmı</düşünce><cevap>Cevap Kısmı</cevap>\"\n",
        ")\n",
        "\n",
        "\n",
        "def make_conversation(example):\n",
        "    secenekler = [a + b for a,b in zip([\"A)\",\"B)\",\"C)\",\"D)\",\"E)\"],example[\"secenekler\"])]\n",
        "    user_content = example[\"soru\"] + \" Seçenekler: \" + \" \".join(secenekler)\n",
        "    return {\n",
        "        \"prompt\": [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": user_content},\n",
        "        ],\n",
        "    }\n",
        "\n",
        "train_dataset = train_dataset.map(make_conversation)\n",
        "train_dataset = train.remove_columns([\"secenekler\",\"soru\"])"
      ],
      "metadata": {
        "trusted": true,
        "id": "f573c07b-94dc-439b-8e97-ed9a9580c755"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "19edd608-3394-4cd2-af56-2716ac8738c8",
      "cell_type": "code",
      "source": [
        "print(train_dataset)"
      ],
      "metadata": {
        "trusted": true,
        "id": "19edd608-3394-4cd2-af56-2716ac8738c8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "64e48fff-a22e-4c24-ab92-77f0b3968ccb",
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "model_id = \"ytu-ce-cosmos/Turkish-Llama-8b-Instruct-v0.1\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "64e48fff-a22e-4c24-ab92-77f0b3968ccb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "43d9f690-c1a6-4756-9c5f-7788f82cfead",
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "trusted": true,
        "id": "43d9f690-c1a6-4756-9c5f-7788f82cfead"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5562e6cc-916a-4c1c-bf79-3eccb968b45a",
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "def format_reward(completions, **kwargs):\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"^<duşünce>.*?</düşünce>\\s*<cevap>.*?</cevap>$\"\n",
        "    completion_contents = [completion[0][\"content\"] for completion in completions]\n",
        "    matches = [re.match(pattern, content) for content in completion_contents]\n",
        "    rewards_list = [1.0 if match else 0.0 for match in matches]\n",
        "    return [1.0 if match else 0.0 for match in matches]"
      ],
      "metadata": {
        "trusted": true,
        "id": "5562e6cc-916a-4c1c-bf79-3eccb968b45a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "61b49cd6-c211-4001-9f26-212c69aa3e25",
      "cell_type": "code",
      "source": [
        "def accuracy_reward(completions, **kwargs):\n",
        "    \"\"\"Reward function that checks if the completion is the same as the ground truth.\"\"\"\n",
        "    solutions = kwargs[\"solution\"]\n",
        "    completion_contents = [completion[0][\"content\"] for completion in completions]\n",
        "    rewards = []\n",
        "    for content, solution in zip(completion_contents, solutions):\n",
        "        correct_letter = correct_answer.upper()\n",
        "        # Regex to find standalone option letters (A-E) followed by optional ')' and punctuation/whitespace\n",
        "        option_pattern = re.compile(r'\\b([A-E])\\)?(?=\\s|\\.|,|$)', re.IGNORECASE)\n",
        "        matches = option_pattern.findall(response.upper())\n",
        "        letters_found = [m.upper() for m in matches]\n",
        "\n",
        "        # Check if correct_letter is present and no incorrect letters are mentioned\n",
        "        if correct_letter in letters_found and all(letter == correct_letter for letter in letters_found):\n",
        "            rewards.append(1.0)  # Full reward for correct answer and no other options\n",
        "        else:\n",
        "            rewards.append(0.0)  # No reward otherwise\n",
        "    return rewards"
      ],
      "metadata": {
        "trusted": true,
        "id": "61b49cd6-c211-4001-9f26-212c69aa3e25"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "71bfcf44-d55e-469c-9d20-369eafdcfe06",
      "cell_type": "code",
      "source": [
        "from trl import GRPOConfig\n",
        "\n",
        "# Configure training arguments using GRPOConfig\n",
        "training_args = GRPOConfig(\n",
        "    output_dir=\"Cosmos-8B-GRPO\",\n",
        "    learning_rate=1e-5,\n",
        "    remove_unused_columns=False,  # to access the solution column in accuracy_reward\n",
        "    gradient_accumulation_steps=16,\n",
        "    num_train_epochs=1,\n",
        "    bf16=True,\n",
        "    # Parameters that control de data preprocessing\n",
        "    max_completion_length=64,  # default: 256\n",
        "    num_generations=4,  # default: 8\n",
        "    max_prompt_length=128,  # default: 512\n",
        "    # Parameters related to reporting and saving\n",
        "    report_to=\"wandb\",\n",
        "    logging_steps=10,\n",
        "    push_to_hub=True,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=10,\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "71bfcf44-d55e-469c-9d20-369eafdcfe06"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0fdfc883-9e88-498f-8780-9fb898de5222",
      "cell_type": "code",
      "source": [
        "from trl import GRPOTrainer\n",
        "\n",
        "trainer = GRPOTrainer(\n",
        "    model=model, reward_funcs=[format_reward, accuracy_reward], args=training_args, train_dataset=train_dataset\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "0fdfc883-9e88-498f-8780-9fb898de5222"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ee14158d-e30a-4465-b2a6-2137b7629087",
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "wandb.finish()"
      ],
      "metadata": {
        "trusted": true,
        "id": "ee14158d-e30a-4465-b2a6-2137b7629087"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6465abde-2414-4732-b6a9-ba2cab7385a7",
      "cell_type": "code",
      "source": [
        "trainer.save_model(training_args.output_dir)\n",
        "trainer.push_to_hub(dataset_name=dataset_id)"
      ],
      "metadata": {
        "trusted": true,
        "id": "6465abde-2414-4732-b6a9-ba2cab7385a7"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}