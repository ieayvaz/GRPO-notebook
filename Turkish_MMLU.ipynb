{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "29f3de3e-7a5d-4b28-a675-7db20104022c",
      "cell_type": "code",
      "source": [
        "!pip install  -U -q trl peft math_verify wandb\n",
        "# Tested with transformers==4.47.1, trl==0.14.0, datasets==3.2.0, peft==0.14.0, accelerate==1.2.1, math_verify==0.3.3"
      ],
      "metadata": {
        "trusted": true,
        "id": "29f3de3e-7a5d-4b28-a675-7db20104022c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "15510df5-7dfb-4451-8c77-d57642ac7cbe",
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "trusted": true,
        "id": "15510df5-7dfb-4451-8c77-d57642ac7cbe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()\n",
        "\n",
        "# Name the project\n",
        "%env WANDB_PROJECT=Qwen2-0.5B-GRPO-test"
      ],
      "metadata": {
        "id": "BdwP3GYJ42Rk"
      },
      "id": "BdwP3GYJ42Rk",
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "e53374a9-0c65-4d8e-950f-1573af1d2f22",
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_id = \"AI-MO/NuminaMath-TIR\"\n",
        "train_dataset, test_dataset = load_dataset(dataset_id, split=[\"train[:5%]\", \"test[:5%]\"])"
      ],
      "metadata": {
        "trusted": true,
        "id": "e53374a9-0c65-4d8e-950f-1573af1d2f22"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "09f6bdb2-b27d-4cdb-92a0-4b8e45d8a0be",
      "cell_type": "code",
      "source": [
        "# Test dataset\n",
        "print(train_dataset[0])"
      ],
      "metadata": {
        "trusted": true,
        "id": "09f6bdb2-b27d-4cdb-92a0-4b8e45d8a0be"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f573c07b-94dc-439b-8e97-ed9a9580c755",
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = (\n",
        "    \"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant \"\n",
        "    \"first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning \"\n",
        "    \"process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., \"\n",
        "    \"<think> reasoning process here </think><answer> answer here </answer>\"\n",
        ")\n",
        "\n",
        "\n",
        "def make_conversation(example):\n",
        "    return {\n",
        "        \"prompt\": [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": example[\"problem\"]},\n",
        "        ],\n",
        "    }\n",
        "\n",
        "\n",
        "train_dataset = train_dataset.map(make_conversation)\n",
        "test_dataset = test_dataset.map(make_conversation)"
      ],
      "metadata": {
        "trusted": true,
        "id": "f573c07b-94dc-439b-8e97-ed9a9580c755"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "19edd608-3394-4cd2-af56-2716ac8738c8",
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.remove_columns([\"messages\", \"problem\"])\n",
        "print(train_dataset)"
      ],
      "metadata": {
        "trusted": true,
        "id": "19edd608-3394-4cd2-af56-2716ac8738c8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "64e48fff-a22e-4c24-ab92-77f0b3968ccb",
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model_id = \"Qwen/Qwen2-0.5B-Instruct\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "64e48fff-a22e-4c24-ab92-77f0b3968ccb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "43d9f690-c1a6-4756-9c5f-7788f82cfead",
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "trusted": true,
        "id": "43d9f690-c1a6-4756-9c5f-7788f82cfead"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5562e6cc-916a-4c1c-bf79-3eccb968b45a",
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "def format_reward(completions, **kwargs):\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"^<think>.*?</think>\\s*<answer>.*?</answer>$\"\n",
        "    completion_contents = [completion[0][\"content\"] for completion in completions]\n",
        "    matches = [re.match(pattern, content) for content in completion_contents]\n",
        "    rewards_list = [1.0 if match else 0.0 for match in matches]\n",
        "    return [1.0 if match else 0.0 for match in matches]"
      ],
      "metadata": {
        "trusted": true,
        "id": "5562e6cc-916a-4c1c-bf79-3eccb968b45a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "61b49cd6-c211-4001-9f26-212c69aa3e25",
      "cell_type": "code",
      "source": [
        "from math_verify import LatexExtractionConfig, parse, verify\n",
        "\n",
        "\n",
        "def accuracy_reward(completions, **kwargs):\n",
        "    \"\"\"Reward function that checks if the completion is the same as the ground truth.\"\"\"\n",
        "    solutions = kwargs[\"solution\"]\n",
        "    completion_contents = [completion[0][\"content\"] for completion in completions]\n",
        "    rewards = []\n",
        "    for content, solution in zip(completion_contents, solutions):\n",
        "        gold_parsed = parse(solution, extraction_mode=\"first_match\", extraction_config=[LatexExtractionConfig()])\n",
        "        answer_parsed = parse(content, extraction_mode=\"first_match\", extraction_config=[LatexExtractionConfig()])\n",
        "        if len(gold_parsed) != 0:\n",
        "            try:\n",
        "                rewards.append(float(verify(answer_parsed, gold_parsed)))\n",
        "            except Exception:\n",
        "                rewards.append(0.0)\n",
        "        else:\n",
        "            rewards.append(1.0)\n",
        "    return rewards"
      ],
      "metadata": {
        "trusted": true,
        "id": "61b49cd6-c211-4001-9f26-212c69aa3e25"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "71bfcf44-d55e-469c-9d20-369eafdcfe06",
      "cell_type": "code",
      "source": [
        "from trl import GRPOConfig\n",
        "\n",
        "# Configure training arguments using GRPOConfig\n",
        "training_args = GRPOConfig(\n",
        "    output_dir=\"Qwen2-0.5B-GRPO-test\",\n",
        "    learning_rate=1e-5,\n",
        "    remove_unused_columns=False,  # to access the solution column in accuracy_reward\n",
        "    gradient_accumulation_steps=16,\n",
        "    num_train_epochs=1,\n",
        "    bf16=True,\n",
        "    # Parameters that control de data preprocessing\n",
        "    max_completion_length=64,  # default: 256\n",
        "    num_generations=4,  # default: 8\n",
        "    max_prompt_length=128,  # default: 512\n",
        "    # Parameters related to reporting and saving\n",
        "    report_to=\"wandb\",\n",
        "    logging_steps=10,\n",
        "    push_to_hub=True,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=10,\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "71bfcf44-d55e-469c-9d20-369eafdcfe06"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0fdfc883-9e88-498f-8780-9fb898de5222",
      "cell_type": "code",
      "source": [
        "from trl import GRPOTrainer\n",
        "\n",
        "trainer = GRPOTrainer(\n",
        "    model=model, reward_funcs=[format_reward, accuracy_reward], args=training_args, train_dataset=train_dataset\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "0fdfc883-9e88-498f-8780-9fb898de5222"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ee14158d-e30a-4465-b2a6-2137b7629087",
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "wandb.finish()"
      ],
      "metadata": {
        "trusted": true,
        "id": "ee14158d-e30a-4465-b2a6-2137b7629087"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6465abde-2414-4732-b6a9-ba2cab7385a7",
      "cell_type": "code",
      "source": [
        "trainer.save_model(training_args.output_dir)\n",
        "trainer.push_to_hub(dataset_name=dataset_id)"
      ],
      "metadata": {
        "trusted": true,
        "id": "6465abde-2414-4732-b6a9-ba2cab7385a7"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}
